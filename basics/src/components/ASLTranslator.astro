<div class="translator-container">
  <div class="translator-card">
    <div class="header">
      <h1>Speech to ASL</h1>
      <p class="subtitle">Real-time American Sign Language translation</p>
    </div>
    
    <div class="input-section">
      <div class="controls">
        <button id="startRecording" class="button primary">
          <span class="icon">üé§</span>
          <span class="button-text">Start</span>
          <div class="ripple"></div>
        </button>
        <button id="stopRecording" class="button secondary" disabled>
          <span class="icon">‚èπ</span>
          <span class="button-text">Stop</span>
          <div class="ripple"></div>
        </button>
      </div>
      
      <div class="transcript-box">
        <div class="box-header">
          <h3>Transcript</h3>
          <div class="status-indicator">
            <span class="status-dot"></span>
            <span class="status-text">Ready</span>
          </div>
        </div>
        <div id="transcript" class="transcript-content">
          Your speech will appear here...
        </div>
      </div>
    </div>

    <div class="output-section">
      <div class="box-header">
        <h3>ASL Translation</h3>
        <div class="status-indicator">
          <span class="status-dot"></span>
          <span class="status-text">Waiting</span>
        </div>
      </div>
      <div class="asl-display">
        <div id="aslAnimation" class="asl-animation">
          <video id="outputVideo" controls class="asl-video"></video>
          <div class="placeholder-content">
            <span class="placeholder-icon">üëã</span>
            <p>ASL signs will be displayed here...</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<style>
  .translator-container {
    min-height: 100vh;
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 2rem;
    background: #fafafa;
  }

  .translator-card {
    background: white;
    border-radius: 24px;
    box-shadow: 
      0 1px 2px rgba(0, 0, 0, 0.02),
      0 2px 4px rgba(0, 0, 0, 0.02),
      0 4px 8px rgba(0, 0, 0, 0.02),
      0 8px 16px rgba(0, 0, 0, 0.02);
    padding: 3rem;
    width: 100%;
    max-width: 720px;
    transition: transform 0.3s ease, box-shadow 0.3s ease;
  }

  .translator-card:hover {
    transform: translateY(-2px);
    box-shadow: 
      0 1px 2px rgba(0, 0, 0, 0.03),
      0 2px 4px rgba(0, 0, 0, 0.03),
      0 4px 8px rgba(0, 0, 0, 0.03),
      0 8px 16px rgba(0, 0, 0, 0.03);
  }

  .header {
    text-align: center;
    margin-bottom: 4rem;
  }

  h1 {
    margin: 0 0 0.75rem;
    font-size: 3rem;
    font-weight: 700;
    color: #111;
    letter-spacing: -0.03em;
    font-family: 'Inter', sans-serif;
  }

  .subtitle {
    color: #666;
    font-size: 1.125rem;
    margin: 0;
    font-family: 'Inter', sans-serif;
    font-weight: 400;
    letter-spacing: -0.01em;
  }

  h3 {
    margin: 0;
    font-size: 1.125rem;
    font-weight: 600;
    color: #111;
    font-family: 'Inter', sans-serif;
    letter-spacing: -0.01em;
  }

  .input-section, .output-section {
    margin-bottom: 3rem;
  }

  .box-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 1.25rem;
  }

  .status-indicator {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    font-size: 0.875rem;
    color: #666;
    font-family: 'Inter', sans-serif;
  }

  .status-dot {
    width: 6px;
    height: 6px;
    border-radius: 50%;
    background: #ccc;
    transition: background-color 0.3s ease;
  }

  .status-dot.recording {
    background: #ff4444;
    animation: pulse 1.5s infinite;
  }

  .status-dot.processing {
    background: #ffbb33;
    animation: pulse 1.5s infinite;
  }

  .status-dot.ready {
    background: #00C851;
  }

  @keyframes pulse {
    0% { transform: scale(1); opacity: 1; }
    50% { transform: scale(1.5); opacity: 0.5; }
    100% { transform: scale(1); opacity: 1; }
  }

  .controls {
    display: flex;
    gap: 1rem;
    margin-bottom: 2.5rem;
  }

  .button {
    position: relative;
    display: flex;
    align-items: center;
    gap: 0.75rem;
    padding: 1rem 2rem;
    border: none;
    border-radius: 16px;
    font-size: 1rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.3s ease;
    overflow: hidden;
    font-family: 'Inter', sans-serif;
  }

  .button .icon {
    font-size: 1.25rem;
  }

  .button .ripple {
    position: absolute;
    border-radius: 50%;
    background: rgba(255, 255, 255, 0.3);
    transform: scale(0);
    animation: ripple 0.6s linear;
    pointer-events: none;
  }

  @keyframes ripple {
    to {
      transform: scale(4);
      opacity: 0;
    }
  }

  .button:disabled {
    opacity: 0.5;
    cursor: not-allowed;
    transform: none;
  }

  .primary {
    background: #111;
    color: white;
  }

  .primary:hover:not(:disabled) {
    transform: translateY(-2px);
    background: #000;
  }

  .primary:active:not(:disabled) {
    transform: translateY(0);
  }

  .secondary {
    background: #f5f5f5;
    color: #111;
  }

  .secondary:hover:not(:disabled) {
    background: #eee;
    transform: translateY(-2px);
  }

  .secondary:active:not(:disabled) {
    transform: translateY(0);
  }

  .transcript-box, .asl-display {
    background: #fafafa;
    border: 1px solid #eee;
    border-radius: 16px;
    padding: 1.75rem;
    transition: all 0.3s ease;
  }

  .transcript-box:hover, .asl-display:hover {
    border-color: #e0e0e0;
  }

  .transcript-content {
    min-height: 100px;
    color: #333;
    line-height: 1.6;
    font-size: 1.125rem;
    font-family: 'Inter', sans-serif;
  }

  .asl-animation {
    min-height: 200px;
    display: flex;
    align-items: center;
    justify-content: center;
    color: #666;
  }

  .asl-video {
    width: 100%;
    max-width: 600px;
    border-radius: 12px;
    margin-bottom: 1rem;
    background: #000;
  }

  .placeholder-content {
    text-align: center;
    display: block;
  }

  .asl-video[src] + .placeholder-content {
    display: none;
  }

  .placeholder-icon {
    font-size: 2.5rem;
    margin-bottom: 1rem;
    display: block;
  }

  .placeholder-content p {
    margin: 0;
    font-size: 1rem;
    color: #666;
    font-family: 'Inter', sans-serif;
  }

  @media (max-width: 768px) {
    .translator-container {
      padding: 1rem;
    }

    .translator-card {
      padding: 2rem;
      border-radius: 20px;
    }

    h1 {
      font-size: 2.25rem;
    }

    .subtitle {
      font-size: 1rem;
    }

    .controls {
      flex-direction: column;
    }

    .button {
      width: 100%;
      justify-content: center;
      padding: 0.875rem 1.5rem;
    }

    .transcript-box, .asl-display {
      padding: 1.25rem;
    }
  }
</style>

<script>
  let audioContext: AudioContext | null = null;
  let recorder: Recorder | null = null;
  let gumStream: MediaStream | null = null;

  const startBtn = document.getElementById("startRecording") as HTMLButtonElement;
  const stopBtn = document.getElementById("stopRecording") as HTMLButtonElement;
  const transcriptBox = document.getElementById("transcript") as HTMLDivElement;
  const aslAnimation = document.getElementById("aslAnimation") as HTMLDivElement;

  if (!startBtn || !stopBtn || !transcriptBox || !aslAnimation) {
    console.error("Required elements not found");
  }

  class Recorder {
    private context: AudioContext;
    private node: ScriptProcessorNode;
    private buffer: Float32Array[];
    private recording: boolean;

    constructor(source: MediaStreamAudioSourceNode) {
      this.context = source.context as AudioContext;
      this.node = this.context.createScriptProcessor(4096, 1, 1);
      this.buffer = [];
      this.recording = false;

      this.node.onaudioprocess = (e: AudioProcessingEvent) => {
        if (!this.recording) return;
        this.buffer.push(new Float32Array(e.inputBuffer.getChannelData(0)));
      };
      source.connect(this.node);
      this.node.connect(this.context.destination);
    }

    record(): void {
      this.recording = true;
    }

    stop(): void {
      this.recording = false;
    }

    exportWAV(cb: (blob: Blob) => void): void {
      let flatBuffer = this.flattenArray();
      let wavBlob = this.encodeWAV(flatBuffer);
      cb(wavBlob);
    }

    private flattenArray(): Float32Array {
      let length = 0;
      for (let i = 0; i < this.buffer.length; i++) length += this.buffer[i].length;
      let result = new Float32Array(length);
      let offset = 0;
      for (let i = 0; i < this.buffer.length; i++) {
        result.set(this.buffer[i], offset);
        offset += this.buffer[i].length;
      }
      return result;
    }

    private encodeWAV(samples: Float32Array): Blob {
      const buffer = new ArrayBuffer(44 + samples.length * 2);
      const view = new DataView(buffer);

      this.writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + samples.length * 2, true);
      this.writeString(view, 8, 'WAVE');

      this.writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, this.context.sampleRate, true);
      view.setUint32(28, this.context.sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);

      this.writeString(view, 36, 'data');
      view.setUint32(40, samples.length * 2, true);

      this.floatTo16BitPCM(view, 44, samples);

      return new Blob([view], { type: 'audio/wav' });
    }

    private writeString(view: DataView, offset: number, string: string): void {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    private floatTo16BitPCM(output: DataView, offset: number, input: Float32Array): void {
      for (let i = 0; i < input.length; i++, offset += 2) {
        let s = Math.max(-1, Math.min(1, input[i]));
        s = s < 0 ? s * 0x8000 : s * 0x7FFF;
        output.setInt16(offset, s, true);
      }
    }
  }

  // Add ripple effect to buttons
  document.querySelectorAll('.button').forEach(button => {
    button.addEventListener('click', (e: Event) => {
      const mouseEvent = e as MouseEvent;
      const rect = button.getBoundingClientRect();
      const x = mouseEvent.clientX - rect.left;
      const y = mouseEvent.clientY - rect.top;
      
      const ripple = button.querySelector('.ripple') as HTMLElement;
      if (ripple) {
        ripple.style.left = `${x}px`;
        ripple.style.top = `${y}px`;
        ripple.style.animation = 'none';
        ripple.offsetHeight; // Trigger reflow
        ripple.style.animation = 'ripple 0.6s linear';
      }
    });
  });

  // Update status indicators
  const transcriptStatus = document.querySelector('.transcript-box .status-dot');
  const aslStatus = document.querySelector('.asl-display .status-dot');
  const transcriptStatusText = document.querySelector('.transcript-box .status-text') as HTMLElement;
  const aslStatusText = document.querySelector('.asl-display .status-text') as HTMLElement;

  function updateStatus(
    dot: Element | null,
    text: Element | null,
    status: 'recording' | 'processing' | 'ready' | 'error' | 'waiting',
    statusText: string
  ) {
    if (dot) {
      dot.className = 'status-dot ' + status;
    }
    if (text) {
      text.textContent = statusText;
    }
  }

  async function fetchVideo(text: string) {
    try {
      updateStatus(aslStatus, aslStatusText, 'processing', 'Converting to ASL');
      
      console.log('Sending text to API:', text);
      const response = await fetch('https://flaskapitext2video.onrender.com/translate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ text: text })
      });

      if (!response.ok) {
    const error = await response.json();
    console.error("Error fetching ASL video:", error.error);  // ‚úÖ backend message
    throw new Error(`Failed to fetch video: ${response.status}`);
  }

      // Check the content type of the response
      const contentType = response.headers.get('content-type');
      console.log('Response content type:', contentType);

      // Get the response as blob
      const blob = await response.blob();
      console.log('Received blob:', blob.type, blob.size);

      // Create video URL
      const videoUrl = URL.createObjectURL(blob);
      const videoElement = document.getElementById('outputVideo') as HTMLVideoElement;
      
      if (videoElement) {
        // Set video source
        videoElement.src = videoUrl;
        
        // Add event listeners for debugging
        videoElement.onloadeddata = () => {
          console.log('Video data loaded');
          updateStatus(aslStatus, aslStatusText, 'ready', 'Ready');
        };
        
        videoElement.onerror = (e) => {
          console.error('Error loading video:', e);
          updateStatus(aslStatus, aslStatusText, 'error', 'Error loading video');
        };

        // Force video to load
        videoElement.load();
        
        // Log video element state
        console.log('Video element state:', {
          src: videoElement.src,
          readyState: videoElement.readyState,
          error: videoElement.error
        });
      }
    } catch (error) {
      console.error('Error fetching ASL video:', error);
      updateStatus(aslStatus, aslStatusText, 'error', 'Error');
    }
  }

  startBtn?.addEventListener('click', async () => {
    try {
      audioContext = new AudioContext();
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      gumStream = stream;

      const input = audioContext.createMediaStreamSource(stream);
      recorder = new Recorder(input);
      recorder.record();

      transcriptBox.textContent = "Recording...";

      startBtn.disabled = true;
      stopBtn.disabled = false;
      
      // Update status indicators
      updateStatus(transcriptStatus, transcriptStatusText, 'recording', 'Recording');
      updateStatus(aslStatus, aslStatusText, 'waiting', 'Waiting for speech');
    } catch (err) {
      transcriptBox.textContent = "Microphone access denied or error.";
      aslAnimation.textContent = "Error accessing microphone";
      console.error(err);
    }
  });

  stopBtn?.addEventListener('click', () => {
    if (!recorder || !gumStream) return;

    recorder.stop();
    gumStream.getAudioTracks().forEach(track => track.stop());

    transcriptBox.textContent = "Processing audio...";

    
    // Update status indicators
    updateStatus(transcriptStatus, transcriptStatusText, 'processing', 'Processing');

    
    recorder.exportWAV(async (blob) => {
      const formData = new FormData();
      formData.append('file', blob, 'audio.wav');

      try {
        const response = await fetch('https://flaskapispeech2text.onrender.com/transcribe', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error("Server error:", errorText);
          transcriptBox.textContent = `Server error: ${response.status}`;
          aslAnimation.textContent = "Error processing speech";
          
          // Update status indicators
          updateStatus(transcriptStatus, transcriptStatusText, 'error', 'Error');
          updateStatus(aslStatus, aslStatusText, 'error', 'Error');
          return;
        }

        const data = await response.json();
        const transcription = data.transcription || "No speech detected.";
        transcriptBox.textContent = transcription;
        
        // Update status indicators
        updateStatus(transcriptStatus, transcriptStatusText, 'ready', 'Ready');


        // Convert transcription to ASL
        await fetchVideo(transcription);
      } catch (err) {
        transcriptBox.textContent = "Error transcribing speech.";
        aslAnimation.textContent = "Error in translation";
        console.error(err);
        
        // Update status indicators
        updateStatus(transcriptStatus, transcriptStatusText, 'error', 'Error');
        updateStatus(aslStatus, aslStatusText, 'error', 'Error');
      }

      startBtn.disabled = false;
      stopBtn.disabled = true;
      
    });

  });
  

</script>